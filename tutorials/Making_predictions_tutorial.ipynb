{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "z5P-C_axoZtu",
        "zs51VrLpfeGF",
        "6h5MSyBKXlWr",
        "6iBQORoffLpc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritraghsh09/GaMPEN/blob/master/tutorials/Making_predictions_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions with GaMPEN\n",
        "\n",
        "In this Jupyter Notebook, we will demonstrate how trained GaMPEN models can be used to make predictions on galaxy images. For an extensive documentation on GaMPEN, please refer to https://gampen.readthedocs.io/en/latest/index.html\n",
        "\n",
        "This tutorial has been developed by [Aritra Ghosh](http://ghosharitra.com) and [Aayush Mishra](https://github.com/aayush2505)."
      ],
      "metadata": {
        "id": "5nQBRCp_Y2x4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary stuff"
      ],
      "metadata": {
        "id": "z5P-C_axoZtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to GPU runtime\n",
        "\n",
        "Before we dive in, note that Google Colab gives you the ability to use GPUs for this tutorial.  \n",
        "\n",
        "To do this, on the Google Colab menu bar select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\"."
      ],
      "metadata": {
        "id": "VIyEb8TRfO6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing GaMPEN\n",
        "\n",
        "First, let's install GaMPEN. \n",
        "\n",
        "Some of these commands are specifically for Google Colab. If doing this on your own machine, please follow the steps outlined [here](https://gampen.readthedocs.io/en/latest/Getting_Started.html)"
      ],
      "metadata": {
        "id": "zs51VrLpfeGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH5faSb1eoTs"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aritraghsh09/GaMPEN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GaMPEN/\n",
        "\n",
        "!pip install -r requirements.txt "
      ],
      "metadata": {
        "id": "MiblqUUEf8av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Installation\n",
        "\n",
        "In order to check whether the installation has occured succesfully, run the command below.  "
      ],
      "metadata": {
        "id": "pKve2eIdhuPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!make check"
      ],
      "metadata": {
        "id": "JRhDz5Okg1kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As long as the tests do not produce any errors, you are good to go! \n",
        "\n",
        "Note that warnings and and tests being skipped are ok! "
      ],
      "metadata": {
        "id": "a3rNg_EYfcdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Images & Models to Perform Prediction"
      ],
      "metadata": {
        "id": "YWnzYF1Oe5GF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading Images and Creating the Necessary Folder Structure\n",
        "\n",
        "Let's get some Hyper Suprime Cam images from its 2nd Public Data Release that we can use to perform predictions. For this demo, we will use the images from Fig. 13 of [Ghosh et. al. 2022](https://arxiv.org/pdf/2212.00051.pdf)\n",
        "\n",
        "**⚠ NOTE:** In order for GaMPEN to work, you need to point it to a `/data/` folder which has all the key components it needs (this folder doesn't necessarily need to be name).  In the data folder, at the very least, you should have \n",
        "  * a `/cutouts/` folder with all the images on which you want to perform analysis\n",
        "  * an `info.csv` file with file names of the various images."
      ],
      "metadata": {
        "id": "6h5MSyBKXlWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create two data-directories in our Colab runtime\n",
        "# One containing low-z images and one containing mid-z images. \n",
        "%cd /content/\n",
        "!mkdir data_lowz\n",
        "!mkdir data_lowz/cutouts/\n",
        "!mkdir data_midz\n",
        "!mkdir data_midz/cutouts/"
      ],
      "metadata": {
        "id": "5neVc-uBwQRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's get some contents for these folders from the Yale FTP Servers\n",
        "\n",
        "%cd /content/data_lowz/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/gampen_tutorial_files/for_preds/data_lowz/info.csv \n",
        "\n",
        "%cd /content/data_lowz/cutouts/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/gampen_tutorial_files/for_preds/data_lowz/cutouts/*.fits\n",
        "\n",
        "%cd /content/data_midz/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/gampen_tutorial_files/for_preds/data_midz/info.csv \n",
        "\n",
        "%cd /content/data_midz/cutouts/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/gampen_tutorial_files/for_preds/data_midz/cutouts/*.fits"
      ],
      "metadata": {
        "id": "WilIIGeRw2Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the Trained Models\n",
        "\n",
        "Now, let's download the models we trained on Hyper Suprime Cam Imaging in [Ghosh et. al. 2022](https://arxiv.org/pdf/2212.00051.pdf). Since our images are from the low and mid redshift bins, we download the corresponding trained models. "
      ],
      "metadata": {
        "id": "6iBQORoffLpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir trained_models\n",
        "%cd trained_models\n",
        "\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/g_0_025/trained_model/g_0_025_real_data.pt\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/r_025_050/trained_model/r_025_050_real_data.pt"
      ],
      "metadata": {
        "id": "qlx7BsEZ5QdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**⚠ NOTE:** Details about all the publicly-available GaMPEN models as well as the morphological catalogs for all galaxies in [Ghosh et. al. 2022](https://arxiv.org/pdf/2212.00051.pdf) can be found in our [Public Data Release Handbook](https://gampen.readthedocs.io/en/latest/Public_data.html)"
      ],
      "metadata": {
        "id": "VYtltwxV_BY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting the Files\n",
        "\n",
        "\n",
        "Now, let's take a quick look at the downloaded info.csv files."
      ],
      "metadata": {
        "id": "RM1AFnDaeEPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "info_lowz = pd.read_csv(\"/content/data_lowz/info.csv\")\n",
        "info_midz = pd.read_csv(\"/content/data_midz/info.csv\")"
      ],
      "metadata": {
        "id": "WH-GJvK9eBau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_lowz"
      ],
      "metadata": {
        "id": "IhyqJJZfedtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_midz"
      ],
      "metadata": {
        "id": "3IYT6jtPegQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As outlined before, the only mandatory coulmn in the info.csv file is a column called `file_name` with the full name of each image file in the `/cutouts/` folder.\n",
        "\n",
        "\n",
        "Now, let's take a quick look at the images. Note that HSC's cutout tool sometimes returns images with slightly different cutout-sizes (in terms of pixels). Thus, if you are using our models for performing inference, we recommend downloading cutouts that are at least 250x250 pixels. Then, using the correct options in GaMPEN, these will be cropped automatically while performing inference. \n",
        "\n",
        "Our pre-trained models accept the following sizes as input sizes for their images:-\n",
        "\n",
        "* Low-z: $239 \\times 239$ pixels\n",
        "* Mid-z: $143 \\times 143$ pixels\n",
        "* High-z: $96 \\times 96$ pixels\n",
        "\n",
        "Inspite of the fact the GaMPEN automatically crops galaxies, we still start out with different sizes for each redshift bin as training & inference time goes down drastically with reduction in image size. Thus, it makes no senese to start with the same sizes for the low- and high-z bins. Each size above is chosen such that most galaxies at these redshifts will have $10 \\times R_e < $ cutout size. "
      ],
      "metadata": {
        "id": "gDmCJzWVejYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "U8MqAj_PhXWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "import matplotlib as mpl\n",
        "from astropy.io import fits\n",
        "\n",
        "LOGMIN = 1e-3\n",
        "\n",
        "#Defining a function to crop images\n",
        "def crop_center(img, cropx, cropy):\n",
        "    \n",
        "    #Function from \n",
        "    #https://stackoverflow.com/questions/39382412/crop-center-portion-of-a-numpy-image\n",
        "    \n",
        "    y, x, *_ = img.shape\n",
        "    startx = x // 2 - (cropx // 2)\n",
        "    starty = y // 2 - (cropy // 2)    \n",
        "    return img[starty:starty + cropy, startx:startx + cropx, ...]"
      ],
      "metadata": {
        "id": "zwyLeKRNf2jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Low-z Data\n",
        "fig, ax = plt.subplots(1,2,figsize=(7,3))\n",
        "\n",
        "for i,img_num in enumerate([45849776612206843, 71112151477012948]):\n",
        "  img_data = fits.getdata('/content/data_lowz/cutouts/' + str(img_num) + '.fits')\n",
        "\n",
        "  #Now, let's crop the image to it's starting size\n",
        "  img_data = crop_center(img_data, 239, 239)\n",
        "\n",
        "  ax[i].imshow(img_data,norm=mpl.colors.LogNorm(vmin=max(img_data.min(),LOGMIN)))"
      ],
      "metadata": {
        "id": "04XmkY3QhhVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mid-z Data\n",
        "fig, ax = plt.subplots(1,2,figsize=(7,3))\n",
        "\n",
        "for i,img_num in enumerate([38544642832100143, 40163802552993641]):\n",
        "  img_data = fits.getdata('/content/data_midz/cutouts/' + str(img_num) + '.fits')\n",
        "\n",
        "  #Now, let's crop the image to it's starting size\n",
        "  img_data = crop_center(img_data, 143, 143)\n",
        "\n",
        "  ax[i].imshow(img_data,norm=mpl.colors.LogNorm(vmin=max(img_data.min(),LOGMIN)))"
      ],
      "metadata": {
        "id": "3FtwWRxVhjNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Inference module\n",
        "\n",
        "Now using the downloaded models and images, let's perform inference."
      ],
      "metadata": {
        "id": "1umWWY934xyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Low-z\n",
        "\n",
        "First, let's use the lowz model to perform inference on the lowz images.\n",
        "\n",
        "For performing inference, first we need to create a directory to store the output files. Let's call this directory `bayesian_inference_runs`.\n",
        "\n",
        "Additionally since we will be using models that have already been trained, we will be making predictions for the following three variables:-\n",
        "\n",
        "$$ \\left( \\log\\frac{L_B/L_T}{1-L_B/L_T}, \\log R_e, \\log \\mathrm{Flux} \\right) $$\n",
        "\n",
        "The variables were additionally standard-scaled (i.e., mean subtracted and variance set to 1) during training (for more details see Section 4.1 of [Ghosh et. al. 2022](https://arxiv.org/pdf/2212.00051.pdf)). Now, in order to perform the inverse scaling properly, we need access to the different training values of these variables that were used to perform the forward scaling.\n",
        "\n",
        "We make a separate directory called `scaling_data_lowz` and `scaling_data_midz` to place the relevant `info.csv` and `/splits/` files from the Yale FTP Servers. These were the files used for training and will help us unscale the predicted values back to ($L_B/L_T$,$R_e$, Flux). You should use the same options for these options if you are using our pre-trained models (as well as the corresponding options for the mid and high-z models)"
      ],
      "metadata": {
        "id": "kSWe8sFjEL8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir bayesian_inference_runs_lowz\n",
        "%mkdir scaling_data_dir_lowz\n",
        "%mkdir scaling_data_dir_lowz/splits/\n",
        "\n",
        "%cd /content/scaling_data_dir_lowz/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/g_0_025/scaling_data_dir/info.csv\n",
        "\n",
        "%cd /content/scaling_data_dir_lowz/splits/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/g_0_025/scaling_data_dir/splits/*.csv"
      ],
      "metadata": {
        "id": "JjEickCsN_Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The backbone of performing inference is the `inference.py` file at `/GaMPEN/ggt/modules/`.\n",
        "\n",
        "In order to use this file, we run it by passing different variables to the inferece file. In order to understand the various options that can be specified while running inference you can type `!python GaMPEN/ggt/modules/inference.py --help` in a Google Colab code cell or consult the documentation [here](https://gampen.readthedocs.io/en/latest/Using_GaMPEN.html#inference). \n",
        "\n",
        "****⚠ STOP: We strongly recommend that you go through the page linked above to understand the various options we have used for performing inference below.**. \n",
        "\n",
        "Since the data we are using for inference doesn't have any ground-truth data available, we set `split` and `slug` to `None` and pass the `--no-labels` option to specify that we don't have any labels available for these images. \n",
        "\n",
        "In order to unscale the predictions back, we specify the path to the appropriate `scaling_data_dir` that we created in the previous step. We specify the `scaling_slug` as `balanced-dev2` since this was the option that was used for the pre-trained model and the scaling file we are using is named `balanced-dev2-train.csv`. All that is done using this file is that the full range of values for the prediction columns specified are read in --> their mean and standard deviation is determined --> and this is then used for unscaling the predicted values. If you are using your own trained models, you should of course point this to the relevant file in `/splits/` in your trainin data directory. \n",
        "\n",
        "The `--mc-dropout` and `--cov-errors` options specify that we want to perform both Monte Carlo dropout during inference as well include aleatoric errors in each of the Monte Carlo runs. The `n_runs` parameter controls the number of different Monte Carlo models generated for prediction. For a robust analysis, we recommend setting this to `500` or `1000`. We set this to `50` here just for demonstrative purposes. \n",
        "\n"
      ],
      "metadata": {
        "id": "7s7z7CPmnAgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "!python GaMPEN/ggt/modules/inference.py\\\n",
        "  --model_path='trained_models/g_0_025_real_data.pt'\\\n",
        "  --output_path=\"bayesian_inference_runs_lowz/\"\\\n",
        "  --data_dir='data_lowz/'\\\n",
        "  --split=None\\\n",
        "  --slug=None\\\n",
        "  --cutout_size=239\\\n",
        "  --normalize\\\n",
        "  --transform\\\n",
        "  --n_workers=2\\\n",
        "  --parallel\\\n",
        "  --label_cols='custom_logit_bt,ln_R_e_asec,ln_total_flux_adus'\\\n",
        "  --model_type='vgg16_w_stn_oc_drp'\\\n",
        "  --repeat_dims\\\n",
        "  --channels=3\\\n",
        "  --label_scaling='std'\\\n",
        "  --mc_dropout\\\n",
        "  --cov_errors\\\n",
        "  --dropout_rate=0.0004\\\n",
        "  --n_runs=50\\\n",
        "  --no-labels\\\n",
        "  --scaling_data_dir='scaling_data_dir_lowz/'\\\n",
        "  --scaling_slug='balanced-dev2'\n"
      ],
      "metadata": {
        "id": "UNenDhbndsR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that output `.csv` files are stored in the output directory we specified. As many `.csv` files are created as the number of runs specified in `n_runs` and are named `inf_xx.csv`. Each file corresponds to the values predicted using a different model created using Monte Carlo Dropout. Each file will contain one sampled value from the predicted distribution by that model.\n",
        "\n",
        "Let's take a look at `inf_1.csv`"
      ],
      "metadata": {
        "id": "R14OjnIjBN0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "inf_1 = pd.read_csv('/content/bayesian_inference_runs_lowz/inf_1.csv')\n",
        "inf_1"
      ],
      "metadata": {
        "id": "6FFgF7H3BNdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected we have the predicted values for each columns specified during inference. Note that these have already been un-scaled in terms of the the minmax/standard scaling specified. However, they are still in the format \n",
        "\n",
        "$$ \\left( \\log\\frac{L_B/L_T}{1-L_B/L_T}, \\log R_e, \\log \\mathrm{Flux} \\right) $$\n",
        "\n",
        "\n",
        "Now, we will use the [`result_aggregator.py`](https://github.com/aritraghsh09/GaMPEN/blob/master/ggt/modules/result_aggregator.py) file in GaMPEN to collate all these .csvs. The `result_aggregator` module of GaMPEN will collect all the csvs; scale the values back to $L_B/L_T$, $R_e$, Flux; produce summary statistics; as well as produce PDFs of the output variables for each image. \n",
        "\n",
        "**For an understanding of all the options available in the `result_aggregator` module, please refere to [this page.](https://gampen.readthedocs.io/en/latest/Using_GaMPEN.html#result-aggregator)**\n",
        "\n",
        "The `data_dir` must point to the directory with the output csvs and the `out_summary_df_path` to the location you want the summary data-frame to be stored. \n",
        "\n",
        "The `unscale` option here specifies that we want to perform the inverse logit and logarithmic scalings. The `scaling_data_dir` should again point to the scaling files used during training (see previous discussion)."
      ],
      "metadata": {
        "id": "sRUQE5LBCtb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir lowz_pdfs\n",
        "\n",
        "!python /content/GaMPEN/ggt/modules/result_aggregator.py\\\n",
        "    --data_dir=\"bayesian_inference_runs_lowz/\"\\\n",
        "    --num=50\\\n",
        "    --out_summary_df_path=\"bayesian_inference_runs_lowz/summary.csv\"\\\n",
        "    --out_pdfs_path=\"lowz_pdfs/\"\\\n",
        "    --unscale\\\n",
        "    --scaling_df_path=\"scaling_data_dir_lowz/info.csv\"\\\n",
        "    --drop_old"
      ],
      "metadata": {
        "id": "1KuXgAKzJdWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's inspect the `summary.csv` file as well as the predicted PDFs. \n"
      ],
      "metadata": {
        "id": "WV9fp10ExWus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "summary_lowz = pd.read_csv('/content/bayesian_inference_runs_lowz/summary.csv')\n",
        "summary_lowz"
      ],
      "metadata": {
        "id": "3KX-3feUx1gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary_lowz.columns)"
      ],
      "metadata": {
        "id": "vMrT0RAtzPdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen in the summary file, for every prediction column we have the \n",
        "\n",
        "  * mean (_mean)\n",
        "  * median (_median)\n",
        "  * mode (_mode)\n",
        "  * standard deviation (_std)\n",
        "  * skewness (_skew)\n",
        "  * kurtosis (_kurt)\n",
        "  * $1\\sigma$ confidence interval (_sig_ci)\n",
        "  * $2\\sigma$ confidence interval (_twosig_ci)\n",
        "  * $3\\sigma$ confidence interval (_threesig_ci)\n",
        "\n",
        "for the predicted distribution. \n",
        "\n",
        "**⚠ STOP: Note that the `result_aggregator` module also converts flux to magnitudes; however this coversion assumes a photometric zeropoint that is only true for HSC. If you are using the `result_aggregator` module for some other survey, you should change this.**\n"
      ],
      "metadata": {
        "id": "FoRyviaFyL2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mid-z\n",
        "\n",
        "Now, let's repeat the same as above, but now using midz model on the midz images."
      ],
      "metadata": {
        "id": "kdzZ67TAUkTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir bayesian_inference_runs_midz\n",
        "%mkdir scaling_data_dir_midz\n",
        "%mkdir scaling_data_dir_midz/splits/\n",
        "\n",
        "%cd /content/scaling_data_dir_midz/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/r_025_050/scaling_data_dir/info.csv\n",
        "\n",
        "%cd /content/scaling_data_dir_midz/splits/\n",
        "!wget ftp://ftp.astro.yale.edu/pub/hsc_morph/r_025_050/scaling_data_dir/splits/*.csv"
      ],
      "metadata": {
        "id": "g0rpZXUfUkTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that below we have updated all variables according the mid-z model. "
      ],
      "metadata": {
        "id": "O4KSK-2H-owV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "!python GaMPEN/ggt/modules/inference.py\\\n",
        "  --model_path='trained_models/r_025_050_real_data.pt'\\\n",
        "  --output_path=\"bayesian_inference_runs_midz/\"\\\n",
        "  --data_dir='data_midz/'\\\n",
        "  --split=None\\\n",
        "  --slug=None\\\n",
        "  --cutout_size=143\\\n",
        "  --normalize\\\n",
        "  --transform\\\n",
        "  --n_workers=2\\\n",
        "  --parallel\\\n",
        "  --label_cols='custom_logit_bt,ln_R_e_asec,ln_total_flux_adus'\\\n",
        "  --model_type='vgg16_w_stn_oc_drp'\\\n",
        "  --repeat_dims\\\n",
        "  --channels=3\\\n",
        "  --label_scaling='std'\\\n",
        "  --mc_dropout\\\n",
        "  --cov_errors\\\n",
        "  --dropout_rate=0.0002\\\n",
        "  --n_runs=50\\\n",
        "  --no-labels\\\n",
        "  --scaling_data_dir='scaling_data_dir_midz/'\\\n",
        "  --scaling_slug='balanced-dev2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO4wr_6YVm-R",
        "outputId": "5078c0fc-c221-4009-b374-185f0c6784ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "[2022-12-15 05:47:11,618] Performing pure inference without labels. Using\n",
            "            column names to infer number of expected outputs.\n",
            "            Split and Slug values entered will be ignored and\n",
            "            info.csv will be used.\n",
            "[2022-12-15 05:47:11,619] Loading images to device...\n",
            "[2022-12-15 05:47:11,622] Generating PyTorch tensors from FITS files...\n",
            "100% 2/2 [00:00<00:00, 9177.91it/s]\n",
            "[2022-12-15 05:47:11,623] Preloading 2 tensors...\n",
            "  0% 0/2 [07:28<?, ?it/s]\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir midz_pdfs\n",
        "\n",
        "!python /content/GaMPEN/ggt/modules/result_aggregator.py\\\n",
        "    --data_dir=\"bayesian_inference_runs_midz/\"\\\n",
        "    --num=50\\\n",
        "    --out_summary_df_path=\"bayesian_inference_runs_midz/summary.csv\"\\\n",
        "    --out_pdfs_path=\"midz_pdfs/\"\\\n",
        "    --unscale\\\n",
        "    --scaling_df_path=\"scaling_data_dir_midz/info.csv\"\\\n",
        "    --drop_old"
      ],
      "metadata": {
        "id": "LaLwQfM5wkHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "summary_midz = pd.read_csv('/content/bayesian_inference_runs_midz/summary.csv')\n",
        "summary_midz"
      ],
      "metadata": {
        "id": "CloG_B5W0Qzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_midz[\"preds_R_e_asec_sig_ci\"][1].split(',')[0][1:]"
      ],
      "metadata": {
        "id": "Ido8-7qfMsdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_midz[\"preds_R_e_asec_sig_ci\"][1].split(',')[1][:-1]"
      ],
      "metadata": {
        "id": "0PRAEMbhM_0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Results\n",
        "\n",
        "Now, let's make a plot for the predicted distributions against the images."
      ],
      "metadata": {
        "id": "qcbGOfN3wufs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required packages & Defining Functions"
      ],
      "metadata": {
        "id": "k57mZvNLhp1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3\n",
        "\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import random\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.ticker import FormatStrFormatter, ScalarFormatter\n",
        "from astropy.io import fits \n",
        "LOGMIN=1e-4"
      ],
      "metadata": {
        "id": "04vDMjeiWuOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hists(summary_file_path,\n",
        "               imgdir, pdf_dir,\n",
        "               font_size=15,\n",
        "               cutout_size=239):\n",
        "  \n",
        "  summary_df = pd.read_csv(summary_file_path)\n",
        "\n",
        "  fig,ax1 = plt.subplots(len(summary_df),4,figsize=(4*5.3,len(summary_df)*4),\n",
        "                          gridspec_kw={'width_ratios': [0.65, 1, 1, 1]})\n",
        "  fig.subplots_adjust(wspace=0.12,hspace=0.23)\n",
        "\n",
        "  row_counter = 0\n",
        "\n",
        "  for i, img_num in enumerate(summary_df[\"object_id\"]):\n",
        "        \n",
        "    ax = ax1[row_counter]\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "        \n",
        "    img_data = fits.getdata(imgdir\n",
        "                            + str(img_num) + \".fits\")\n",
        "    img_data = crop_center(img_data,cutout_size,cutout_size)\n",
        "    ax[0].imshow(img_data,norm=mpl.colors.LogNorm(vmin=max(img_data.min(),LOGMIN)))\n",
        "\n",
        "    pred_arr = np.load(pdf_dir + str(img_num) + \".npy\")\n",
        "  \n",
        "    pred_cols = [\"preds_bt\",\"preds_R_e_asec\",\"preds_total_mag\"]\n",
        "    pred_arr_idxs = [2,0,3] #indexes of columns in pred_arr\n",
        "\n",
        "    for j, column_name in enumerate(pred_cols):\n",
        "\n",
        "      ax[j+1].plot(pred_arr[pred_arr_idxs[j]],\n",
        "                   pred_arr[pred_arr_idxs[j]+4],\n",
        "                   label=\"PDF\",lw=3)\n",
        "      \n",
        "\n",
        "      mode = summary_df[column_name + \"_mode\"][i]\n",
        "      sig_ci = summary_df[column_name + \"_sig_ci\"][i]\n",
        "      sig_ci = (float(sig_ci.split(',')[0][1:]),\n",
        "                float(sig_ci.split(',')[1][:-1]))\n",
        "      twosig_ci = summary_df[column_name + \"_twosig_ci\"][i]\n",
        "      twosig_ci = (float(twosig_ci.split(',')[0][1:]),\n",
        "                   float(twosig_ci.split(',')[1][:-1]))\n",
        "      threesig_ci = summary_df[column_name + \"_threesig_ci\"][i]\n",
        "      threesig_ci = (float(threesig_ci.split(',')[0][1:]),\n",
        "                     float(threesig_ci.split(',')[1][:-1]))\n",
        "      n_out = pred_arr[pred_arr_idxs[j]+4]\n",
        "      \n",
        "      ax[j+1].plot([mode,mode],[0,np.max(pred_arr[pred_arr_idxs[j]+4])],c='r',\n",
        "                      ls='solid',label=\"Mode\", lw =3) #plotting a x = Mode line\n",
        "            \n",
        "            \n",
        "            \n",
        "      rect = Rectangle((sig_ci[0], 0), sig_ci[1]-sig_ci[0], 0.25*np.max(n_out),color='coral',\n",
        "                             alpha=0.5,label=\"68.27 %ile\",lw=1)\n",
        "      border = Rectangle((sig_ci[0], 0), sig_ci[1]-sig_ci[0], 0.25*np.max(n_out),ec='coral',\n",
        "                             lw=3,fill=False)\n",
        "      ax[j+1].add_patch(rect)  \n",
        "      ax[j+1].add_patch(border)\n",
        "    \n",
        "      rect = Rectangle((twosig_ci[0], 0), twosig_ci[1]-twosig_ci[0], 0.175*np.max(n_out),color='goldenrod',\n",
        "                             alpha=0.5,label=\"95.45 %ile\")\n",
        "      border = Rectangle((twosig_ci[0], 0), twosig_ci[1]-twosig_ci[0], 0.175*np.max(n_out),ec='goldenrod',\n",
        "                             lw=3,fill=False)\n",
        "      ax[j+1].add_patch(rect)\n",
        "      ax[j+1].add_patch(border)\n",
        "    \n",
        "      rect = Rectangle((threesig_ci[0], 0), threesig_ci[1]-threesig_ci[0], 0.10*np.max(n_out),\n",
        "                             color='seagreen',alpha=0.5,label=\"99.73 %ile\")\n",
        "      border = Rectangle((threesig_ci[0], 0), threesig_ci[1]-threesig_ci[0], 0.10*np.max(n_out),ec='seagreen',\n",
        "                             lw=3,fill=False)\n",
        "      ax[j+1].add_patch(rect)\n",
        "      ax[j+1].add_patch(border)\n",
        "            \n",
        "            \n",
        "            \n",
        "      #ax[j+1].ticklabel_format(axis='both',style='sci',scilimits=(0,0))\n",
        "      ax[j+1].set_yticks([])\n",
        "      ax[j+1].tick_params(axis='x',labelsize=font_size-3)\n",
        "            \n",
        "                \n",
        "    if row_counter == 0:\n",
        "            ax[1].legend(loc='upper right',prop={'size': font_size-4})\n",
        "            \n",
        "                \n",
        "              \n",
        "    row_counter += 1\n",
        "\n",
        "\n",
        "  ax[1].set_xlabel(r\"$L_B/L_T$\",fontsize=font_size)\n",
        "  ax[2].set_xlabel(r\"$R_e$ (asec)\",fontsize=font_size)\n",
        "  ax[3].set_xlabel(r\"mag (g-band)\",fontsize=font_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "PZhY47Oo6OkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Plots"
      ],
      "metadata": {
        "id": "XRJKP6DaTApE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hists(imgdir=\"/content/data_lowz/cutouts/\",\n",
        "           summary_file_path=\"/content/bayesian_inference_runs_lowz/summary.csv\",\n",
        "           pdf_dir=\"/content/lowz_pdfs/\",\n",
        "           font_size=18)"
      ],
      "metadata": {
        "id": "b86ps-NQ6c23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hists(imgdir=\"/content/data_midz/cutouts/\",\n",
        "           summary_file_path=\"/content/bayesian_inference_runs_midz/summary.csv\",\n",
        "           pdf_dir=\"/content/midz_pdfs/\",\n",
        "           font_size=18,\n",
        "           cutout_size=143)"
      ],
      "metadata": {
        "id": "HN2sJ9YASnik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}